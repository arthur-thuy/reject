{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diversity Quality (DQ) score\n",
    "\n",
    "The Diversity Quality score measures how close the diversity on the in-distribution (ID) and out-of-distribution (OOD) datasets is to the ideal diversity. On the ID set, diversity should be small, while on the OOD set, diversity should be large. The DQ score is the harmonic mean of (1 - ID diversity) and OOD diversity. The $DQ_1$-score is calculated as follows:\n",
    "\n",
    "$$DQ_1 = 2 \\cdot \\frac{(1 - IDD) \\cdot OODD}{(1 - IDD) + OODD}$$\n",
    "\n",
    "The $DQ_1$ score can also be generalized to a $DQ_\\beta$ score, valuing one of ID diversity or OOD diversity more than the other.\n",
    "With $\\beta$ a positive real factor, OODD is considered $\\beta$ times as important as IDD:\n",
    "\n",
    "$$DQ_\\beta = (1 + \\beta^2) \\cdot \\frac{(1 - IDD) \\cdot OODD}{\\beta^2 \\cdot (1 - IDD) + OODD}$$\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import reject\n",
    "from reject.utils import generate_synthetic_output\n",
    "from reject.diversity import diversity_quality_score, diversity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.0\n"
     ]
    }
   ],
   "source": [
    "print(reject.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic NN output\n",
    "\n",
    "In this example, we generate synthetic outputs of a NN with multiple samples of the predictive distribution. The output predictions are of shape `(n_observations, n_samples, n_classes)` and the true labels `(n_observations,)`. The data generation function uses 10 output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10, 10) (1000,)\n",
      "(1000, 10, 10) (1000,)\n"
     ]
    }
   ],
   "source": [
    "NUM_SAMPLES = 10\n",
    "NUM_OBSERVATIONS = 1000\n",
    "\n",
    "(y_pred_id, y_true_id), (y_pred_ood, y_true_ood) = generate_synthetic_output(\n",
    "    NUM_SAMPLES, NUM_OBSERVATIONS, concat=False\n",
    ")\n",
    "print(y_pred_id.shape, y_true_id.shape)\n",
    "print(y_pred_ood.shape, y_true_ood.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diversity score\n",
    "\n",
    "We first calculate the diversity scores on the ID and OOD sets. The diversity score is calculated as the fraction of test data points on which predictions of ensemble members disagree. As the base model for diversity computation, we average the output distributions over the members and determine the resulting predicted label.\n",
    "\n",
    "The `diversity_score` functions directly takes the predictions. You can choose the get the diversity for each member or the average diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.437 0.436 0.451 0.428 0.439 0.416 0.431 0.434 0.422 0.441]\n",
      "0.4335000000000001\n"
     ]
    }
   ],
   "source": [
    "# ID set - diversity for each member\n",
    "div_score = diversity_score(y_pred=y_pred_id, average=False)\n",
    "print(div_score)\n",
    "\n",
    "# ID set - average diversity\n",
    "div_score = diversity_score(y_pred=y_pred_id, average=True)\n",
    "print(div_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.667 0.671 0.655 0.653 0.641 0.644 0.698 0.665 0.662 0.662]\n",
      "0.6618\n"
     ]
    }
   ],
   "source": [
    "# OOD set - diversity for each member\n",
    "div_score = diversity_score(y_pred=y_pred_ood, average=False)\n",
    "print(div_score)\n",
    "\n",
    "# OOD set - average diversity\n",
    "div_score = diversity_score(y_pred=y_pred_ood, average=True)\n",
    "print(div_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the diversity scores on the OOD set are higher than the diversity scores on the ID set. This is expected and is desired in real-life applications.\n",
    "\n",
    "## $DQ_1$-score\n",
    "\n",
    "Based on the ID and OOD diversities, we calculate the $DQ_1$-score.\n",
    "\n",
    "The `diversity_quality_score` function directly takes in the ID and OOD predictions. You can choose the get the diversity for each member or the average diversity. By default, the $DQ_1$-score is calculated, which gives equal weight to the ID and OOD diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61060325 0.61286478 0.59733389 0.60982204 0.59833777 0.6125342\n",
      " 0.62693291 0.61151909 0.61715484 0.60615561]\n",
      "0.6104529837987462\n"
     ]
    }
   ],
   "source": [
    "# diversity quality for each member\n",
    "dq_score = diversity_quality_score(\n",
    "    y_pred_id=y_pred_id, y_pred_ood=y_pred_ood, average=False\n",
    ")\n",
    "print(dq_score)\n",
    "\n",
    "# average diversity quality\n",
    "dq_score = diversity_quality_score(\n",
    "    y_pred_id=y_pred_id, y_pred_ood=y_pred_ood, average=True\n",
    ")\n",
    "print(dq_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $DQ_\\beta$-score\n",
    "\n",
    "By adapting the `beta_ood` parameter, we can assign a higher weight to either ID or OOD diversity. For example, for `beta_ood=2`, the OOD diversity is considered twice as important as the ID diversity. Conversely, for `beta_ood=0.5`, the ID diversity is considered twice as important as the OOD diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6402583851355967\n",
      "0.5832991567352271\n"
     ]
    }
   ],
   "source": [
    "# beta = 2.0\n",
    "dq_score = diversity_quality_score(\n",
    "    y_pred_id=y_pred_id, y_pred_ood=y_pred_ood, beta_ood=2.0, average=True\n",
    ")\n",
    "print(dq_score)\n",
    "\n",
    "# beta = 0.5\n",
    "dq_score = diversity_quality_score(\n",
    "    y_pred_id=y_pred_id, y_pred_ood=y_pred_ood, beta_ood=0.5, average=True\n",
    ")\n",
    "print(dq_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
